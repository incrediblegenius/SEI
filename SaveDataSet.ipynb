{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from util import ProcessSignal,ProcessSignal16x16,ResampleSignal16x16,ResampleSignal64x64\n",
    "import os\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "data = []\n",
    "emitter = []\n",
    "fs = 186666677\n",
    "savepth = 'alldata_Preprocess64x64'\n",
    "for root,dirs,file in os.walk('./'):\n",
    "    if(root=='./'):\n",
    "        continue\n",
    "    for f in file:\n",
    "        \n",
    "        if f[-4:] =='.dat' :\n",
    "            emitter.append(f.split('_')[-2])\n",
    "            sig = np.memmap(root+'/'+f,dtype='int16',mode='r')\n",
    "            data.append(ProcessSignal(sig,fs))\n",
    "            # data.append(ResampleSignal64x64(sig))\n",
    "\n",
    "emset = list(set(emitter))\n",
    "a = [i for i in range(len(emset))]\n",
    "emi = dict(zip(emset,a))\n",
    "target = [emi[i] for i in emitter]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# import h5py\n",
    "# from collections import defaultdict\n",
    "\n",
    "# d = defaultdict(list)\n",
    "\n",
    "# for i in range(len(emitter)):\n",
    "#     key = emitter[i]\n",
    "#     d[key].append(data[i])\n",
    "\n",
    "# f = h5py.File('./dataset/'+savepth+'.h5', 'w')\n",
    "# for key in emset:\n",
    "#     f.create_dataset(key,data=d[key])\n",
    "# f.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# with h5py.File('./dataset/'+savepth+'.h5', 'r') as f :\n",
    "#     s = np.array(f['780609'][:])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "temp = np.array([data, target])\n",
    "temp = temp.transpose()\n",
    "np.random.shuffle(temp)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipykernel_1980274/1620479978.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  temp = np.array([data, target])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "image_list = list(temp[:, 0])\n",
    "label_list = list(temp[:, 1])\n",
    "label_list = [int(i) for i in label_list] "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "point = (int)(len(image_list)*1//10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_data = []\n",
    "train_lable = []\n",
    "for i in range(point):\n",
    "    train_data.append(image_list[i])\n",
    "    train_lable.append(label_list[i])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_data = []\n",
    "test_lable = []\n",
    "for i in range(point,len(image_list)):\n",
    "    test_data.append(image_list[i])\n",
    "    test_lable.append(label_list[i])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import h5py"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "\n",
    "f = h5py.File(savepth+'.h5', 'w')\n",
    "f.create_dataset('X_train', data=train_data)\n",
    "f.create_dataset('y_train', data=train_lable)\n",
    "f.create_dataset('X_test', data=test_data)\n",
    "f.create_dataset('y_test', data=test_lable)\n",
    "f.close()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "train_dataset = h5py.File(savepth+'.h5', 'r')\n",
    "train_set_x_orig = np.array(train_dataset['X_train'][:]) # your train set features\n",
    "train_set_y_orig = np.array(train_dataset['y_train'][:]) # your train set labels\n",
    "test_set_x_orig = np.array(train_dataset['X_test'][:]) # your train set features\n",
    "test_set_y_orig = np.array(train_dataset['y_test'][:]) # your train set labels\n",
    "f.close()\n",
    " \n",
    "#读写测试\n",
    "print(train_set_x_orig.shape)\n",
    "print(train_set_y_orig.shape)\n",
    " \n",
    "print(train_set_y_orig.max())\n",
    "print(train_set_y_orig.min())\n",
    " \n",
    "print(test_set_x_orig.shape)\n",
    "print(test_set_y_orig.shape)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(6810, 4096)\n",
      "(6810,)\n",
      "33\n",
      "0\n",
      "(27240, 4096)\n",
      "(27240,)\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "fb02ac6f80c2960f85351c91d39b082ff33e615006ccb793b463b41ffb5114c0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}